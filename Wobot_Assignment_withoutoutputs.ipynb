{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Wobot Assignment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K57HW9JoprUF"
      },
      "source": [
        "**Cloning tensorflow models**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "bY7ho-KIXeqn"
      },
      "source": [
        "import os\r\n",
        "import pathlib\r\n",
        "if \"models\" in pathlib.Path.cwd().parts:\r\n",
        "  while \"models\" in pathlib.Path.cwd().parts:\r\n",
        "    os.chdir('..')\r\n",
        "elif not pathlib.Path('models').exists():\r\n",
        "  !git clone --depth 1 https://github.com/tensorflow/models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Skf1l1nQpn2s"
      },
      "source": [
        "**Installing API**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYgxlU7zYZqg",
        "collapsed": true
      },
      "source": [
        "%%bash\r\n",
        "cd models/research/\r\n",
        "protoc object_detection/protos/*.proto --python_out=.\r\n",
        "cp object_detection/packages/tf2/setup.py .\r\n",
        "python -m pip install ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4r67TdwWZ44J"
      },
      "source": [
        "import matplotlib\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import os\r\n",
        "import random\r\n",
        "import io\r\n",
        "import imageio\r\n",
        "import glob\r\n",
        "import scipy.misc\r\n",
        "import numpy as np\r\n",
        "from six import BytesIO\r\n",
        "from PIL import Image, ImageDraw, ImageFont\r\n",
        "from IPython.display import display, Javascript\r\n",
        "from IPython.display import Image as IPyImage\r\n",
        "import tensorflow as tf\r\n",
        "import tarfile\r\n",
        "import re\r\n",
        "\r\n",
        "from object_detection.utils import label_map_util\r\n",
        "from object_detection.utils import config_util\r\n",
        "from object_detection.utils import visualization_utils as viz_utils\r\n",
        "from object_detection.utils import colab_utils\r\n",
        "from object_detection.builders import model_builder\r\n",
        "\r\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPtPoKbPpzHH"
      },
      "source": [
        "**Testing API**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "vlQMbbtqackW"
      },
      "source": [
        "!python /content/models/research/object_detection/builders/model_builder_tf2_test.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QgjFjrRdp4b-"
      },
      "source": [
        "**Created a shortcut of the dataset from [here](http://shuoyang1213.me/WIDERFACE/) in my personal Google Drive and unzipping them to session storage**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "6tT_Ik5Qqvw6"
      },
      "source": [
        "%%bash\r\n",
        "unzip /content/drive/MyDrive/Colab\\ Notebooks/dataset/WIDER_train.zip\r\n",
        "unzip /content/drive/MyDrive/Colab\\ Notebooks/dataset/WIDER_val.zip\r\n",
        "unzip /content/drive/MyDrive/Colab\\ Notebooks/dataset/wider_face_split.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qR9zJzh8k4cb"
      },
      "source": [
        "%cd /content/WIDER_train/images/\r\n",
        "%mv */* .\r\n",
        "%rm -r */\r\n",
        "%cd /content/WIDER_val/images/\r\n",
        "%mv */* .\r\n",
        "%rm -r */\r\n",
        "%cd /content/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OxjpsjXysNBA"
      },
      "source": [
        "**Modifying gt files with correct paths**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDjhWBBmpD3s"
      },
      "source": [
        "with open(\"/content/wider_face_split/wider_face_train_bbx_gt.txt\", \"r\") as fp:\r\n",
        "    lines = fp.readlines()\r\n",
        "with open(\"/content/wider_face_split/wider_face_train_bbx_gt.txt\", \"wb\") as fp:\r\n",
        "    for line in lines:\r\n",
        "      if(\".jpg\" in line):\r\n",
        "        line = line.rsplit('/',1)[1]\r\n",
        "      fp.write(line.encode())\r\n",
        "with open(\"/content/wider_face_split/wider_face_val_bbx_gt.txt\", \"r\") as fp:\r\n",
        "    lines = fp.readlines()\r\n",
        "with open(\"/content/wider_face_split/wider_face_val_bbx_gt.txt\", \"wb\") as fp:\r\n",
        "    for line in lines:\r\n",
        "      if(\".jpg\" in line):\r\n",
        "        line = line.rsplit('/',1)[1]\r\n",
        "      fp.write(line.encode())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOmntTGckZZ7"
      },
      "source": [
        "**Downloading necessary files**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "nyZQwK4taf-u"
      },
      "source": [
        "%%bash\r\n",
        "wget https://raw.githubusercontent.com/GowthamGottimukkala/wobotai.assignment/main/convert.py\r\n",
        "wget https://raw.githubusercontent.com/GowthamGottimukkala/wobotai.assignment/main/xml_to_csv.py\r\n",
        "wget https://raw.githubusercontent.com/GowthamGottimukkala/wobotai.assignment/main/generate_tfrecord.py\r\n",
        "wget https://raw.githubusercontent.com/GowthamGottimukkala/wobotai.assignment/main/generate_pbtxt.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNh_5c7XqJ3O"
      },
      "source": [
        "**Preparing data for the TF OD API**\r\n",
        "\r\n",
        "*Converting from Widerface annotation format to xml and then to tfrecord*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "l13Kt5y2fw-e"
      },
      "source": [
        "%%bash\r\n",
        "python convert.py -ap /content/wider_face_split/wider_face_train_bbx_gt.txt -tp /content/XML_train -ip /content/WIDER_train/images\r\n",
        "python xml_to_csv.py -xmlp /content/XML_train/ -tp /content/train.csv\r\n",
        "python convert.py -ap /content/wider_face_split/wider_face_val_bbx_gt.txt -tp /content/XML_val -ip /content/WIDER_val/images\r\n",
        "python xml_to_csv.py -xmlp /content/XML_val/ -tp /content/val.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "531U8zbGt0pp",
        "collapsed": true
      },
      "source": [
        "%%bash\r\n",
        "python generate_pbtxt.py csv train.csv labelmap_pb.txt\r\n",
        "python generate_tfrecord.py train.csv labelmap_pb.txt WIDER_train/images train.tfrecords\r\n",
        "python generate_tfrecord.py val.csv labelmap_pb.txt WIDER_val/images val.tfrecords"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDJnjf2EI7XS"
      },
      "source": [
        "**Downloading and extracting model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "Cnf7E8dMI0Pb"
      },
      "source": [
        "%mkdir /content/models/research/deploy/\r\n",
        "!wget http://download.tensorflow.org/models/object_detection/tf2/20200711/efficientdet_d0_coco17_tpu-32.tar.gz -P /content/models/research/deploy\r\n",
        "tarfile.open(\"/content/models/research/deploy/efficientdet_d0_coco17_tpu-32.tar.gz\").extractall(\"/content/models/research/deploy/\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igjbvlDYNzFH"
      },
      "source": [
        "**Inializing parameters**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNWCVP6wH_8Z"
      },
      "source": [
        "num_classes = 1\r\n",
        "num_steps = 1000\r\n",
        "num_eval_steps = 200\r\n",
        "batch_size = 4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5miqBKmMHdTq"
      },
      "source": [
        "**Downloading Configuration File**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "4VFHHz-rD_2V"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/configs/tf2/ssd_efficientdet_d0_512x512_coco17_tpu-8.config -P /content/models/research/deploy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSM0QtFcNTVR"
      },
      "source": [
        "**Writing Custom Configuration file**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSACY9QTLV9U"
      },
      "source": [
        "fine_tune_checkpoint = '/content/models/research/deploy/efficientdet_d0_coco17_tpu-32/checkpoint/ckpt-0'\r\n",
        "%cd /content/models/research/deploy\r\n",
        "\r\n",
        "with open('ssd_efficientdet_d0_512x512_coco17_tpu-8.config') as f:\r\n",
        "    s = f.read()\r\n",
        "with open('pipeline_file.config', 'w') as f:\r\n",
        "    \r\n",
        "    # fine_tune_checkpoint\r\n",
        "    s = re.sub('fine_tune_checkpoint: \".*?\"',\r\n",
        "               'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), s)\r\n",
        "    \r\n",
        "    # tfrecord files train and test.\r\n",
        "    s = re.sub(\r\n",
        "        '(input_path: \".*?)(PATH_TO_BE_CONFIGURED/train)(.*?\")', 'input_path: \"{}\"'.format(\"/content/train.tfrecords\"), s)\r\n",
        "    s = re.sub(\r\n",
        "        '(input_path: \".*?)(PATH_TO_BE_CONFIGURED/val)(.*?\")', 'input_path: \"{}\"'.format(\"/content/val.tfrecords\"), s)\r\n",
        "\r\n",
        "    # label_map_path\r\n",
        "    s = re.sub(\r\n",
        "        'label_map_path: \".*?\"', 'label_map_path: \"{}\"'.format(\"/content/labelmap_pb.txt\"), s)\r\n",
        "\r\n",
        "    # Set training batch_size.\r\n",
        "    s = re.sub('batch_size: [0-9]+',\r\n",
        "               'batch_size: {}'.format(batch_size), s)\r\n",
        "\r\n",
        "    # Set training steps, num_steps\r\n",
        "    s = re.sub('num_steps: [0-9]+',\r\n",
        "               'num_steps: {}'.format(num_steps), s)\r\n",
        "    \r\n",
        "    # Set number of classes num_classes.\r\n",
        "    s = re.sub('num_classes: [0-9]+',\r\n",
        "               'num_classes: {}'.format(num_classes), s)\r\n",
        "    \r\n",
        "    #fine-tune checkpoint type\r\n",
        "    s = re.sub(\r\n",
        "        'fine_tune_checkpoint_type: \"classification\"', 'fine_tune_checkpoint_type: \"{}\"'.format('detection'), s)\r\n",
        "        \r\n",
        "    f.write(s)\r\n",
        "\r\n",
        "%cd /content"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lrYuhCxew88o"
      },
      "source": [
        "!cat /content/models/research/deploy/pipeline_file.config"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1pvavx5HiCf"
      },
      "source": [
        "def load_image_into_numpy_array(path):\r\n",
        "  \"\"\"Load an image from file into a numpy array.\r\n",
        "\r\n",
        "  Puts image into numpy array to feed into tensorflow graph.\r\n",
        "  Note that by convention we put it into a numpy array with shape\r\n",
        "  (height, width, channels), where channels=3 for RGB.\r\n",
        "\r\n",
        "  Args:\r\n",
        "    path: a file path.\r\n",
        "\r\n",
        "  Returns:\r\n",
        "    uint8 numpy array with shape (img_height, img_width, 3)\r\n",
        "  \"\"\"\r\n",
        "  img_data = tf.io.gfile.GFile(path, 'rb').read()\r\n",
        "  image = Image.open(BytesIO(img_data))\r\n",
        "  (im_width, im_height) = image.size\r\n",
        "  return np.array(image.getdata()).reshape(\r\n",
        "      (im_height, im_width, 3)).astype(np.uint8)\r\n",
        "\r\n",
        "def plot_detections(image_np,\r\n",
        "                    boxes,\r\n",
        "                    classes,\r\n",
        "                    scores,\r\n",
        "                    category_index,\r\n",
        "                    figsize=(12, 16),\r\n",
        "                    image_name=None):\r\n",
        "  \"\"\"Wrapper function to visualize detections.\r\n",
        "\r\n",
        "  Args:\r\n",
        "    image_np: uint8 numpy array with shape (img_height, img_width, 3)\r\n",
        "    boxes: a numpy array of shape [N, 4]\r\n",
        "    classes: a numpy array of shape [N]. Note that class indices are 1-based,\r\n",
        "      and match the keys in the label map.\r\n",
        "    scores: a numpy array of shape [N] or None.  If scores=None, then\r\n",
        "      this function assumes that the boxes to be plotted are groundtruth\r\n",
        "      boxes and plot all boxes as black with no classes or scores.\r\n",
        "    category_index: a dict containing category dictionaries (each holding\r\n",
        "      category index `id` and category name `name`) keyed by category indices.\r\n",
        "    figsize: size for the figure.\r\n",
        "    image_name: a name for the image file.\r\n",
        "  \"\"\"\r\n",
        "  image_np_with_annotations = image_np.copy()\r\n",
        "  viz_utils.visualize_boxes_and_labels_on_image_array(\r\n",
        "      image_np_with_annotations,\r\n",
        "      boxes,\r\n",
        "      classes,\r\n",
        "      scores,\r\n",
        "      category_index,\r\n",
        "      use_normalized_coordinates=True,\r\n",
        "      min_score_thresh=0.8)\r\n",
        "  if image_name:\r\n",
        "    plt.imsave(image_name, image_np_with_annotations)\r\n",
        "  else:\r\n",
        "    plt.imshow(image_np_with_annotations)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GevsvXdiio9K"
      },
      "source": [
        "!kill 930\r\n",
        "%rm -rf /content/training"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dr6vGc_aZ2g"
      },
      "source": [
        "%mkdir /content/training\r\n",
        "%load_ext tensorboard\r\n",
        "%tensorboard --logdir '/content/training/train'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "Jz-GqnGVOzZT"
      },
      "source": [
        "!python /content/models/research/object_detection/model_main_tf2.py --pipeline_config_path /content/models/research/deploy/pipeline_file.config --model_dir /content/training/ --alsologtostderr --num_train_steps={num_steps} --sample_1_of_n_eval_examples=1 --num_eval_steps={num_eval_steps}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVppScxvfp5X"
      },
      "source": [
        "!python /content/models/research/object_detection/model_main_tf2.py --model_dir=/content/training/ --pipeline_config_path=/content/models/research/deploy/pipeline_file.config --checkpoint_dir=/content/training/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpafLK3k9SCS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}